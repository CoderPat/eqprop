{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Equilibrium Propagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#TODO: some introduction to energy-based methods and equilibrum propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as np\n",
    "import jax.random as random\n",
    "from jax import grad, jit, vmap\n",
    "\n",
    "import numpy as onp\n",
    "\n",
    "from network import jit_free_relaxation, jit_clamped_relaxation\n",
    "from layerednet import LayeredNet\n",
    "from utils import vmap_mean\n",
    "\n",
    "from random import randint\n",
    "from collections import deque\n",
    "from six.moves.urllib.request import urlretrieve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=20\n",
    "SEED=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, \n",
    "          train_loader,\n",
    "          epochs,\n",
    "          lr=0.1,\n",
    "          valid_loader=None,\n",
    "          valid_interval=200):\n",
    "    \n",
    "    cost_fn = net.cost_fn()\n",
    "    \n",
    "    free_relaxation = jit_free_relaxation(LayeredNet, batched=True)\n",
    "    clamped_relaxation = jit_clamped_relaxation(LayeredNet, lr=lr, batched=True)\n",
    "\n",
    "    for epoch in range(1, epochs+1):\n",
    "        train_hits = 0\n",
    "        for step, (x, y) in enumerate(train_loader()):\n",
    "            # set input and relax states (ie: compute fixed-point)\n",
    "            net.x = x\n",
    "            net = free_relaxation(net)\n",
    "\n",
    "            # log training accuracy\n",
    "            yi = np.argmax(y, axis=1)\n",
    "            pred_yi = np.argmax(net.output, axis=1)\n",
    "            train_hits += np.sum(pred_yi == yi).item()\n",
    "            \n",
    "            # update the weights based on expected output\n",
    "            net = clamped_relaxation(net, y)\n",
    "            \n",
    "        log_string = (\"epoch: {0} | train_acc: {1:.3f}\"\n",
    "                      .format(epoch, float(train_hits) / ((step+1)*BATCH_SIZE)))\n",
    "        \n",
    "        if valid_loader is not None and not epoch % valid_interval:        \n",
    "            hits = 0\n",
    "            for step, (x, y) in enumerate(valid_loader()):\n",
    "                # set input and relax states \n",
    "                net.x = x\n",
    "                net = free_relaxation(net)\n",
    "                \n",
    "                yi = np.argmax(y, axis=1)\n",
    "                pred_yi = np.argmax(net.output, axis=1)\n",
    "                hits += np.sum(pred_yi == yi).item()\n",
    "                \n",
    "            valid_log = (\"valid_acc: {1:.3f}\"\n",
    "                         .format(epoch, float(hits) / ((step+1)*BATCH_SIZE)))\n",
    "            log_string = log_string + \" | \" + valid_log\n",
    "                                                             \n",
    "        print(log_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synthetic Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by training the network on a synthetic dataset. The input consists of a random one-hot vector and the output is simply the identity on this vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def dataloader():\n",
    "    for _ in range(100):\n",
    "        xs, ys = [], []\n",
    "        for _ in range(BATCH_SIZE):\n",
    "            x, y = onp.zeros(3), onp.zeros(3)\n",
    "            j = randint(0, 2)\n",
    "            x[j] = 1\n",
    "            y[j] = 1\n",
    "            xs.append(x)\n",
    "            ys.append(y)\n",
    "        yield np.stack(xs), np.stack(ys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both a network with no hidden layers and a single hidden layer are able to solve the task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = LayeredNet.new(3, 3, [], random.PRNGKey(SEED))\n",
    "net = net.batch(BATCH_SIZE)\n",
    "\n",
    "print(\"Training Depth 0 Network:\")\n",
    "train(\n",
    "    net,\n",
    "    epochs=10,\n",
    "    train_loader=dataloader, \n",
    "    valid_loader=dataloader,\n",
    "    valid_interval=2)\n",
    "print()\n",
    "\n",
    "net = LayeredNet.new(3, 3, [10], random.PRNGKey(SEED))\n",
    "net = net.batch(BATCH_SIZE)\n",
    "\n",
    "\n",
    "print(\"Training Depth 1 Network:\")\n",
    "train(\n",
    "    net,\n",
    "    epochs=10,\n",
    "    train_loader=dataloader, \n",
    "    valid_loader=dataloader,\n",
    "    valid_interval=2)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While a network with more than one hidden layer struggle to solve the task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = LayeredNet.new(3, 3, [10, 10], random.PRNGKey(SEED))\n",
    "net = net.batch(BATCH_SIZE)\n",
    "\n",
    "print(\"Training Depth 2 Network:\")\n",
    "train(\n",
    "    net,\n",
    "    epochs=10,\n",
    "    train_loader=dataloader, \n",
    "    valid_loader=dataloader,\n",
    "    valid_interval=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"mnist.npz\"\n",
    "urlretrieve('https://s3.amazonaws.com/img-datasets/mnist.npz', path)\n",
    "\n",
    "with onp.load(path, allow_pickle=True) as f:\n",
    "    x_train, y_train = f['x_train'].astype(np.float32), f['y_train']\n",
    "    x_test, y_test = f['x_test'].astype(np.float32), f['y_test']\n",
    "    \n",
    "print(\"train size: {0}, test_size: {1}\".format(len(x_train), len(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def train_mnist():\n",
    "    for i in range(0, len(x_train), BATCH_SIZE):\n",
    "        xs = onp.reshape(x_train[i:i+BATCH_SIZE], (-1, 28*28))\n",
    "        ys = np.eye(10)[y_train[i:i+BATCH_SIZE]]\n",
    "        yield xs, ys\n",
    "        \n",
    "def valid_mnist():\n",
    "    for i in range(0, len(x_test), BATCH_SIZE):\n",
    "        xs = onp.reshape(x_test[i:i+BATCH_SIZE], (-1, 28*28))\n",
    "        ys = np.eye(10)[y_test[i:i+BATCH_SIZE]]\n",
    "        yield xs, ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = LayeredNet.new(28*28, 10, [512, 512], random.PRNGKey(SEED))\n",
    "net = net.batch(BATCH_SIZE)\n",
    "\n",
    "lr = [0.4, 0.1, 0.01]\n",
    "lr = [*lr, *lr]\n",
    "\n",
    "train(\n",
    "    net,\n",
    "    epochs=100,\n",
    "    lr=lr,\n",
    "    train_loader=train_mnist, \n",
    "    valid_loader=valid_mnist,\n",
    "    valid_interval=2)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
